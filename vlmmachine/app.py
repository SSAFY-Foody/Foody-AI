import io
import os
import json
import re
from typing import Optional, List, Dict

from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from pydantic import BaseModel
from PIL import Image

import torch
from transformers import AutoProcessor, AutoModelForVision2Seq

from sqlalchemy import create_engine, Column, String, Float, func
from sqlalchemy.orm import sessionmaker, declarative_base, Session

from dotenv import load_dotenv

# =========================
# .env ë¡œë“œ
# =========================
load_dotenv()

# =========================
# SQL ì„¤ì •
# =========================
DATABASE_URL = os.getenv("FOODY_DATABASE_URL")
if not DATABASE_URL:
    raise RuntimeError("FOODY_DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

engine = create_engine(DATABASE_URL, echo=False, future=True)
SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False)
Base = declarative_base()


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# =========================
# ê¸°ì¡´ FOOD í…Œì´ë¸” ë§¤í•‘
# =========================
class Foods(Base):
    __tablename__ = "foods"

    code = Column(String(45), primary_key=True)
    name = Column(String(30), nullable=False)
    standard = Column(String(10), nullable=False)
    kcal = Column(Float, nullable=False, default=0)

    # ì‹¤ì œ DB ì»¬ëŸ¼ ë§¤í•‘
    carb = Column("carb_g", Float, nullable=False, default=0)
    protein = Column("protein_g", Float, nullable=False, default=0)
    fat = Column("fat_g", Float, nullable=False, default=0)
    sugar = Column("sugar_g", Float, nullable=False, default=0)
    natrium = Column("natrium_g", Float, nullable=False, default=0)


# =========================
# ì‘ë‹µ ëª¨ë¸(JSON)
# =========================
class FoodResponse(BaseModel):
    name: str
    standard: str
    kcal: float
    carb: float
    protein: float
    fat: float
    sugar: float
    natrium: float


# =========================
# ìœ í‹¸: ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ ë°˜ì˜¬ë¦¼
# =========================
def round2(value: float) -> float:
    return round(float(value), 2)


# =========================
# Qwen VLM í´ë¼ì´ì–¸íŠ¸ (Base model only)
# =========================
class QwenClient:
    def __init__(self):
        print("[INFO] Loading Qwen2.5-VL-3B-Instruct....")

        self.processor = AutoProcessor.from_pretrained("Qwen/Qwen2.5-VL-3B-Instruct")
        self.model = AutoModelForVision2Seq.from_pretrained(
            "Qwen/Qwen2.5-VL-3B-Instruct",
            torch_dtype=torch.float16,
            device_map="auto",  # GPU ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ CPU
        )
        self.model.eval()
        print("[INFO] Base model loaded successfully (LoRA disabled).")

    def _is_valid_food_name(self, s: str) -> bool:
        if not s:
            return False
        s = s.strip()

        # í”í•œ ì‹¤íŒ¨ í† í°ë“¤
        if s in {"-", "â€”", "_", "?", "ì—†ìŒ", "ëª¨ë¦„", "ì•Œìˆ˜ì—†ìŒ", "ì•Œ ìˆ˜ ì—†ìŒ", "unknown"}:
            return False

        # í•œê¸€ì´ 1ê¸€ì ì´ìƒì€ ìˆì–´ì•¼ ìŒì‹ëª…ìœ¼ë¡œ ì·¨ê¸‰
        if not re.search(r"[ê°€-í£]", s):
            return False

        return True

    def _generate_one(self, pil_image: Image.Image, prompt: str) -> str:
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": pil_image},
                    {"type": "text", "text": prompt},
                ],
            }
        ]

        inputs = self.processor.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt",
        ).to(self.model.device)

        output = self.model.generate(
            **inputs,
            max_new_tokens=20,
            do_sample=False,
        )

        text = self.processor.decode(
            output[0][inputs["input_ids"].shape[-1] :],
            skip_special_tokens=True,
        ).strip()

        # ê³µë°±/ë¬¸ì¥ ì„ì—¬ ë‚˜ì˜¬ ë•Œ ëŒ€ë¹„
        text = text.split()[0].strip()

        # ë”°ì˜´í‘œ/ê´„í˜¸ ë“± ì œê±°
        text = re.sub(r"[\"'()\[\]{}<>]", "", text).strip()

        return text

    def _post_process_food_name(self, food_name: str) -> str:
        """ì˜ì–´ ìŒì‹ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë³€í™˜í•˜ê³  ê²€ì¦"""
        translations = {
            "omelette": "ì˜¤ë¯ˆë ›",
            "omelet": "ì˜¤ë¯ˆë ›",
            "eggroll": "ê³„ë€ë§ì´",
            "egg roll": "ê³„ë€ë§ì´",
            "koreaneggroll": "ê³„ë€ë§ì´",
            "korean egg roll": "ê³„ë€ë§ì´",
            "rolledegg": "ê³„ë€ë§ì´",
            "rolled egg": "ê³„ë€ë§ì´",
            "salad": "ìƒëŸ¬ë“œ",
            "rice": "ë°¥",
            "kimchi": "ê¹€ì¹˜",
            "kimbap": "ê¹€ë°¥",
            "ramen": "ë¼ë©´",
        }

        lower_name = food_name.lower().strip()

        # ì˜ì–´ ë‹¨ì–´ ê·¸ëŒ€ë¡œ ë§¤ì¹­
        if lower_name in translations:
            return translations[lower_name]

        # ë¶€ë¶„ ì¼ì¹˜ ì²˜ë¦¬
        for eng, kor in translations.items():
            if eng in lower_name:
                return kor

        return food_name

    # 1) ìŒì‹ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ìŒì‹ ëª… ì¶”ë¡ 
    def predict_food_name(self, pil_image: Image.Image) -> str:
        # âœ… 1ì°¨ í”„ë¡¬í”„íŠ¸ (ë„¤ê°€ ì‘ì„±í•œ ê°œì„ ë³¸ì„ "ë¬¸ì¥ ì—°ê²°" ì œëŒ€ë¡œ ë˜ë„ë¡ ì •ë¦¬)
        prompt1 = (
            "ë„ˆëŠ” í•œêµ­ ìŒì‹ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ë‹¤.\n"
            "ì´ë¯¸ì§€ì—ì„œ 'ê°€ì¥ ì¤‘ì‹¬ì´ ë˜ëŠ” ìŒì‹ 1ê°œ'ì˜ ì´ë¦„ë§Œ í•œêµ­ì–´ë¡œ ì¶œë ¥í•´ë¼.\n\n"
            "ì¶œë ¥ ê·œì¹™(ë§¤ìš° ì¤‘ìš”):\n"
            "1) í•œêµ­ì–´ ìŒì‹ëª…ë§Œ ì¶œë ¥\n"
            "2) ì¡°ì‚¬/ë¬¸ì¥/ì„¤ëª… ê¸ˆì§€ (ì˜ˆ: 'ì…ë‹ˆë‹¤', 'ê°™ì•„ìš”', '.' ê¸ˆì§€)\n"
            "3) ë”°ì˜´í‘œ/ê´„í˜¸/ìŠ¬ë˜ì‹œ/ì´ëª¨ì§€ ê¸ˆì§€\n"
            "4) ê³µë°± ì—†ì´ ìŒì‹ëª…ë§Œ ì¶œë ¥ (ìµœëŒ€ 12ì)\n\n"
            "ì˜ˆì‹œ(ì •ë‹µ í˜•ì‹):\n"
            "ê¹€ë°¥\n"
            "ê³„ë€ë§ì´\n"
            "ë–¡ë³¶ì´\n\n"
            "í˜¼ë™ ì£¼ì˜ ê·œì¹™:\n"
            "- ê³„ë€ë§ì´: ë‹¬ê±€ì„ ë§ì•„ ë„¤ëª¨/ì›í†µ í˜•íƒœ, ë‹¨ë©´ì´ ë§ë¦° ì¸µ\n"
            "- ì˜¤ë¯ˆë ›: ì ‘íŒ í˜•íƒœ, ë‘¥ê¸€ê³  ë‚©ì‘í•¨\n\n"
            "ì¤‘ìš”: ì¶œë ¥í•  ìŒì‹ëª…ì´ ì—†ë‹¤ê³  íŒë‹¨ë˜ë”ë¼ë„ '-', 'ì—†ìŒ', '?'ë¥¼ ì¶œë ¥í•˜ì§€ ë§ê³ \n"
            "ê°€ì¥ ìœ ì‚¬í•œ í•œêµ­ ìŒì‹ëª… 1ê°œë¥¼ ë°˜ë“œì‹œ ì¶œë ¥í•˜ë¼.\n\n"
            "ì •ë‹µ(ìŒì‹ëª…ë§Œ):"
        )

        out1 = self._generate_one(pil_image, prompt1)
        out1 = self._post_process_food_name(out1)
        if self._is_valid_food_name(out1):
            return out1

        # âœ… 2ì°¨ í”„ë¡¬í”„íŠ¸(ì¬ì‹œë„) - ë” ê°•í•˜ê²Œ "ë°˜ë“œì‹œ ìŒì‹ëª…"
        prompt2 = (
            "ë„ˆëŠ” í•œêµ­ ìŒì‹ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ë‹¤.\n"
            "ëª¨ë¥´ê² ì–´ë„ '-', '?', 'ì—†ìŒ'ì„ ì¶œë ¥í•˜ì§€ ë§ˆë¼.\n"
            "ê°€ì¥ ìœ ì‚¬í•œ í•œêµ­ ìŒì‹ëª… 1ê°œë¥¼ ë°˜ë“œì‹œ ì¶œë ¥í•˜ë¼.\n"
            "ìŒì‹ëª…ë§Œ ì¶œë ¥(ì„¤ëª… ê¸ˆì§€).\n"
            "ì •ë‹µ:"
        )

        out2 = self._generate_one(pil_image, prompt2)
        out2 = self._post_process_food_name(out2)
        if self._is_valid_food_name(out2):
            return out2

        # âœ… ìµœí›„ fallback: ì˜ˆì „ì²˜ëŸ¼ ì´ìƒê°’ ë…¸ì¶œì„ ë§‰ê¸° ìœ„í•œ ê¸°ë³¸ê°’
        print(f"[WARN] VLM invalid outputs: out1='{out1}', out2='{out2}' -> fallback='ìŒì‹'")
        return "ìŒì‹"

    # 2) (Fallback) ìˆœìˆ˜ LLM ê¸°ë°˜ ì˜ì–‘ ì¶”ë¡  (RAG ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ ë³´ë£¨)
    def estimate_nutrition_llm(self, food_name: str) -> dict:
        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì˜ì–‘í•™ìì…ë‹ˆë‹¤.
"{food_name}" ìŒì‹ì˜ 100g ê¸°ì¤€ ì˜ì–‘ì„±ë¶„ì„ ì¶”ì •í•˜ì„¸ìš”.

â— ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
â— ì„¤ëª…, ë¬¸ì¥, ì½”ë“œë¸”ë¡, ì—¬ë¶„ì˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ë¡œ ë„£ì§€ ë§ˆì„¸ìš”.
â— ëª¨ë“  ìˆ˜ì¹˜ëŠ” number ë¡œ ì¶œë ¥í•˜ì„¸ìš” (ë”°ì˜´í‘œ ê¸ˆì§€)

ì˜ˆì‹œ ì¶œë ¥:
{{
  "standard": "100g",
  "kcal": 154,
  "carb": 3.2,
  "protein": 11.2,
  "fat": 10.1,
  "sugar": 1.1,
  "natrium": 250
}}
        """

        messages = [{"role": "user", "content": [{"type": "text", "text": prompt}]}]

        inputs = self.processor.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt",
        ).to(self.model.device)

        output = self.model.generate(**inputs, max_new_tokens=200)

        text = self.processor.decode(
            output[0][inputs["input_ids"].shape[-1] :],
            skip_special_tokens=True,
        ).strip()

        try:
            json_block = re.search(r"\{.*\}", text, flags=re.S).group(0)
            data = json.loads(json_block)
        except Exception:
            data = {
                "standard": "100g",
                "kcal": 0,
                "carb": 0,
                "protein": 0,
                "fat": 0,
                "sugar": 0,
                "natrium": 0,
            }

        return data


qwen = QwenClient()

# =========================
# Chroma RAG ì„¤ì •
# =========================
import chromadb
from chromadb.utils import embedding_functions

CHROMA_DB_DIR = os.getenv("FOODY_CHROMA_DIR", "./chroma_foods")
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_DIR)

ko_embedding = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name=os.getenv("FOODY_EMBED_MODEL", "jhgan/ko-sroberta-multitask")
)

food_collection = chroma_client.get_or_create_collection(
    name="food_nutrition",
    embedding_function=ko_embedding,
)


def build_chroma_from_db():
    """ì„œë²„ ì‹œì‘ ì‹œ foods í…Œì´ë¸” ë‚´ìš©ì„ Chromaì— ì¸ë±ì‹± (ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ)"""
    count = food_collection.count()
    if count > 0:
        print(f"[INFO] Existing Chroma collection already has {count} items. Skip building.")
        return

    print("[INFO] Building Chroma index from foods table...")

    db = SessionLocal()
    try:
        foods: List[Foods] = db.query(Foods).all()
        total = len(foods)
        print(f"[INFO] Loaded {total} foods from DB.")
    finally:
        try:
            db.close()
        except Exception as e:
            print(f"[WARN] Failed to close DB session cleanly: {e}")

    if total == 0:
        print("[INFO] No foods found in DB to index.")
        return

    batch_size = 128
    for start in range(0, total, batch_size):
        end = min(start + batch_size, total)
        batch = foods[start:end]

        ids = []
        docs = []
        metas = []

        for f in batch:
            ids.append(f.code)
            docs.append(f"{f.name} {f.standard}")
            metas.append(
                {
                    "name": f.name,
                    "standard": f.standard,
                    "kcal": float(f.kcal),
                    "carb": float(f.carb),
                    "protein": float(f.protein),
                    "fat": float(f.fat),
                    "sugar": float(f.sugar),
                    "natrium": float(f.natrium),
                }
            )

        food_collection.add(ids=ids, documents=docs, metadatas=metas)
        print(f"[INFO] Indexed {end}/{total} foods into Chroma...")

    print("[INFO] Finished building Chroma index.")


def rag_estimate_nutrition(food_name: str, top_k: int = 3, distance_threshold: float = 1.0) -> Optional[dict]:
    """Chromaë¡œ ìœ ì‚¬ ìŒì‹ ì˜ì–‘ì •ë³´ ê²€ìƒ‰ ë° ì¶”ì • (Top-1 ì„ íƒ)"""
    result = food_collection.query(query_texts=[food_name], n_results=top_k)

    metadatas = result.get("metadatas", [[]])[0]
    distances = result.get("distances", [[]])[0]
    documents = result.get("documents", [[]])[0]

    if not metadatas:
        print(f"[WARN] No RAG results found for '{food_name}'")
        return None

    # ìƒì„¸ ë¡œê¹…: ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
    print(f"[DEBUG] RAG Search Results for '{food_name}':")
    for i, (doc, meta, dist) in enumerate(zip(documents, metadatas, distances)):
        print(f"  [{i+1}] {doc} | distance={dist:.4f}")
        print(f"      kcal={meta.get('kcal')}, carb={meta.get('carb')}g, "
              f"protein={meta.get('protein')}g, fat={meta.get('fat')}g")

    # ê°€ì¥ ìœ ì‚¬í•œ ê²°ê³¼ ì„ íƒ (Top-1)
    best_meta = metadatas[0]
    best_distance = distances[0]

    # ê±°ë¦¬ ì„ê³„ê°’ ì²´í¬
    if best_distance > distance_threshold:
        print(f"[WARN] Best match distance ({best_distance:.4f}) exceeds threshold ({distance_threshold})")
        print(f"[WARN] Result may be inaccurate for '{food_name}'")

    # Top-1ë§Œ ì‚¬ìš© (í‰ê·  ì œê±°)
    result_data = {
        "standard": best_meta.get("standard", "100g"),
        "kcal": float(best_meta.get("kcal", 0)),
        "carb": float(best_meta.get("carb", 0)),
        "protein": float(best_meta.get("protein", 0)),
        "fat": float(best_meta.get("fat", 0)),
        "sugar": float(best_meta.get("sugar", 0)),
        "natrium": float(best_meta.get("natrium", 0)),
    }

    print(f"[INFO] Selected nutrition data: kcal={result_data['kcal']}, "
          f"carb={result_data['carb']}g, protein={result_data['protein']}g, fat={result_data['fat']}g")

    return result_data


# =========================
# FastAPI ì•± ìƒì„±
# =========================
app = FastAPI(title="Foody - Qwen2.5-VL Analyzer API")


@app.on_event("startup")
def on_startup():
    build_chroma_from_db()


@app.post("/api/vlm/food", response_model=FoodResponse)
async def predict_food(
    image: UploadFile = File(...),
    db: Session = Depends(get_db),
):
    # 1) ì´ë¯¸ì§€ ì²´í¬
    if not image.content_type or not image.content_type.startswith("image/"):
        raise HTTPException(400, "ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    # 2) ì´ë¯¸ì§€ ë¡œë“œ
    try:
        content = await image.read()
        pil_image = Image.open(io.BytesIO(content)).convert("RGB")
    except Exception:
        raise HTTPException(400, "ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 3) ìŒì‹ ì´ë¦„ ì¶”ë¡  (VLM)
    print(f"\n{'='*80}")
    food_name = qwen.predict_food_name(pil_image)
    normalized_name = food_name.replace(" ", "")
    print(f"[INFO] ğŸ” VLM Prediction: '{food_name}' (normalized: '{normalized_name}')")

    # 4) RDB exact match (ê³µë°± ì œê±° ë¹„êµ)
    food = (
        db.query(Foods)
        .filter(func.replace(Foods.name, " ", "") == normalized_name)
        .first()
    )

    # 5) ì˜ì–‘ ì„±ë¶„ ê²°ì • ë¡œì§
    if food:
        # âœ… DBì— ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ìŒì‹ì´ ìˆìœ¼ë©´ DB ë°ì´í„° ì‚¬ìš©
        print(f"[INFO] âœ… Found exact match in DB: '{food.name}' (code: {food.code})")
        print(f"[INFO] ğŸ’¾ Using DB nutrition data directly (skipping RAG)")
        
        response_name = food.name
        est = {
            "standard": food.standard,
            "kcal": float(food.kcal),
            "carb": float(food.carb),
            "protein": float(food.protein),
            "fat": float(food.fat),
            "sugar": float(food.sugar),
            "natrium": float(food.natrium),
        }
    else:
        # DBì— ì—†ìœ¼ë©´ RAGë¡œ ìœ ì‚¬ ìŒì‹ ê²€ìƒ‰
        print(f"[INFO] No exact match in DB for '{normalized_name}'")
        print(f"[INFO] Starting RAG search for '{food_name}'...")
        
        response_name = food_name
        est = rag_estimate_nutrition(food_name)
        
        if est:
            print(f"[INFO] RAG search successful")
        else:
            # RAGë„ ì‹¤íŒ¨í•˜ë©´ LLMìœ¼ë¡œ ì¶”ì •
            print(f"[INFO] RAG failed, using LLM estimation for '{food_name}'")
            est = qwen.estimate_nutrition_llm(food_name)

    # ìµœì¢… ê²°ê³¼ ë¡œê¹…
    print(f"[INFO] ğŸ“Š Final Response:")
    print(f"       name='{response_name}', standard='{est.get('standard')}'")
    print(f"       kcal={round2(est.get('kcal', 0))}, carb={round2(est.get('carb', 0))}g")
    print(f"       protein={round2(est.get('protein', 0))}g, fat={round2(est.get('fat', 0))}g")
    print(f"       sugar={round2(est.get('sugar', 0))}g, natrium={round2(est.get('natrium', 0))}mg")
    print(f"{'='*80}\n")

    return FoodResponse(
        name=response_name,
        standard=est.get("standard", "100"),
        kcal=round2(est.get("kcal", 0)),
        carb=round2(est.get("carb", 0)),
        protein=round2(est.get("protein", 0)),
        fat=round2(est.get("fat", 0)),
        sugar=round2(est.get("sugar", 0)),
        natrium=round2(est.get("natrium", 0)),
    )

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "app:app",
        host="0.0.0.0", 
        port=8000,    
        reload=False      
    )

